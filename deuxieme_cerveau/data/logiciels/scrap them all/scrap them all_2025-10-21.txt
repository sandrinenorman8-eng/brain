07:33:49: Voici la suite – un unique fichier Python contenant :

• le noyau déjà fourni  
• une implémentation « site-restricted » générique (scrape DuckDuckGo)  
• une classe (ou un alias) par moteur/forum cité dans la conversation, toutes dérivant du même SearchEngine  
• l’enregistrement automatique dans les listes WEB_ENGINES et FORUM_ENGINES.

Copiez/collez simplement ce bloc après (ou à la place de) votre ancien script ; tout reste compatible.

```python
# ──────────────────────────────────────────
# search_engines_extended.py
# Complément : couverture des 20 moteurs/forums listés
# ──────────────────────────────────────────
#
#  Rappel : dépendances
#     pip install requests beautifulsoup4
#
#  Utilisation :
#     python search_engines_extended.py "rust borrow checker forum" 15
#
# -------------------------------------------------
import re
# (imports, SearchEngine, SerpAPI, DuckDuckGo, BoardReader, Omgili, Reddit,
#  cascade(), unified_search() etc. déjà définis plus haut)
# -------------------------------------------------

# ──────────────────────────────────────────
# Utilitaire : recherche « site:example.com … » via DuckDuckGo
# ──────────────────────────────────────────
class SiteRestrictedDuck(SearchEngine):
    """
    Moteur générique : s’appuie sur DuckDuckGo (mode HTML)
    en ajoutant le préfixe  site:xxxx  à la requête.
    """
    DUCK_URL = "https://duckduckgo.com/html/"

    def __init__(self, site: str, label: str | None = None):
        self.site = site
        self.label = label or site

    def search(self, query: str, n: int = 10) -> List[str]:
        full_q = f"site:{self.site} {query}"
        res = requests.get(self.DUCK_URL,
                           params={"q": full_q},
                           timeout=15,
                           headers={"User-Agent": "Mozilla/5.0"})
        res.raise_for_status()
        soup  = BeautifulSoup(res.text, "html.parser")
        urls  = [a["href"] for a in soup.select(".result__url")]
        # Duck renvoie parfois une redirection /l/?kh=…
        clean = [re.sub(r"^https?://duckduckgo\.com/l/\\?kh=[^&]+&uddg=", "", u)
                 for u in urls]
        return clean[:n]

    def __repr__(self) -> str:
        return f"<SiteDuck {self.label}>"

# ──────────────────────────────────────────
# Moteurs supplémentaires (20 au total)
# ──────────────────────────────────────────
class GoogleGroups(SiteRestrictedDuck):
    def __init__(self): super().__init__("groups.google.com", "Google Groups")

class StackExchange(SearchEngine):
    """Stack Overflow + Stack Exchange via API officielle"""
    API = "https://api.stackexchange.com/2.3/search/advanced"
    def search(self, query: str, n: int = 10) -> List[str]:
        params = {
            "order": "desc",
            "sort": "relevance",
            "q": query,
            "site": "stackoverflow",
            "pagesize": n
        }
        res = requests.get(self.API, params=params, timeout=15)
        res.raise_for_status()
        data = res.json()
        return [item["link"] for item in data.get("items", [])][:n]

class HackerNews(SearchEngine):
    API = "https://hn.algolia.com/api/v1/search"
    def search(self, query: str, n: int = 10) -> List[str]:
        res = requests.get(self.API, params={"query": query, "hitsPerPage": n}, timeout=15)
        res.raise_for_status()
        return [hit["url"] or f"https://news.ycombinator.com/item?id={hit['objectID']}"
                for hit in res.json().get("hits", [])][:n]

class GitHubDiscussions(SearchEngine):
    def se  Voici la suite – un unique fichier Python contenant :

• le noyau déjà fourni  
• une implémentation « site-restricted » générique (scrape DuckDuckGo)  
• une classe (ou un alias) par moteur/forum cité dans la conversation, toutes dérivant du même SearchEngine  
• l’enregistrement automatique dans les listes WEB_ENGINES et FORUM_ENGINES.

Copiez/collez simplement ce bloc après (ou à la place de) votre ancien script ; tout reste compatible.

```python
# ──────────────────────────────────────────
# search_engines_extended.py
# Complément : couverture des 20 moteurs/forums listés
# ──────────────────────────────────────────
#
#  Rappel : dépendances
#     pip install requests beautifulsoup4
#
#  Utilisation :
#     python search_engines_extended.py "rust borrow checker forum" 15
#
# -------------------------------------------------
import re
# (imports, SearchEngine, SerpAPI, DuckDuckGo, BoardReader, Omgili, Reddit,
#  cascade(), unified_search() etc. déjà définis plus haut)
# -------------------------------------------------

# ──────────────────────────────────────────
# Utilitaire : recherche « site:example.com … » via DuckDuckGo
# ──────────────────────────────────────────
class SiteRestrictedDuck(SearchEngine):
    """
    Moteur générique : s’appuie sur DuckDuckGo (mode HTML)
    en ajoutant le préfixe  site:xxxx  à la requête.
    """
    DUCK_URL = "https://duckduckgo.com/html/"

    def __init__(self, site: str, label: str | None = None):
        self.site = site
        self.label = label or site

    def search(self, query: str, n: int = 10) -> List[str]:
        full_q = f"site:{self.site} {query}"
        res = requests.get(self.DUCK_URL,
                           params={"q": full_q},
                           timeout=15,
                           headers={"User-Agent": "Mozilla/5.0"})
        res.raise_for_status()
        soup  = BeautifulSoup(res.text, "html.parser")
        urls  = [a["href"] for a in soup.select(".result__url")]
        # Duck renvoie parfois une redirection /l/?kh=…
        clean = [re.sub(r"^https?://duckduckgo\.com/l/\\?kh=[^&]+&uddg=", "", u)
                 for u in urls]
        return clean[:n]

    def __repr__(self) -> str:
        return f"<SiteDuck {self.label}>"

# ──────────────────────────────────────────
# Moteurs supplémentaires (20 au total)
# ──────────────────────────────────────────
class GoogleGroups(SiteRestrictedDuck):
    def __init__(self): super().__init__("groups.google.com", "Google Groups")

class StackExchange(SearchEngine):
    """Stack Overflow + Stack Exchange via API officielle"""
    API = "https://api.stackexchange.com/2.3/search/advanced"
    def search(self, query: str, n: int = 10) -> List[str]:
        params = {
            "order": "desc",
            "sort": "relevance",
            "q": query,
            "site": "stackoverflow",
            "pagesize": n
        }
        res = requests.get(self.API, params=params, timeout=15)
        res.raise_for_status()
        data = res.json()
        return [item["link"] for item in data.get("items", [])][:n]

class HackerNews(SearchEngine):
    API = "https://hn.algolia.com/api/v1/search"
    def search(self, query: str, n: int = 10) -> List[str]:
        res = requests.get(self.API, params={"query": query, "hitsPerPage": n}, timeout=15)
        res.raise_for_status()
        return [hit["url"] or f"https://news.ycombinator.com/item?id={hit['objectID']}"
                for hit in res.json().get("hits", [])][:n]

class GitHubDiscussions(SearchEngine):
    def se
